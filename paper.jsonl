{"id":"zhang2025","title":"Advancing Deep Learning through Probability Engineering: A Pragmatic Paradigm for Modern AI","authors":"Jianyi Zhang","journal":"arXiv","year":"2025","doi":"10.48550/arXiv.2503.18958","url":"https://arxiv.org/abs/2503.18958","keyAssumptions":"Probability distributions are static objects to be fitted; traditional probabilistic modeling sufficient for modern AI","keyHypotheses":"Actively modifying and reinforcing learned distributions can better address diverse AI requirements than passive fitting","strengths":"Novel paradigm shift; practical applications across multiple domains; systematic expansion of probabilistic modeling role","weaknesses":"High-level conceptual paper; limited technical implementation details; needs empirical validation","citation":"Zhang, J. (2025). Advancing Deep Learning through Probability Engineering: A Pragmatic Paradigm for Modern AI. arXiv:2503.18958","notes":"Directly relevant to DERP - establishes theoretical foundation for active distribution modification","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"ahmadi2024","title":"Distributional Adversarial Loss","authors":"Saba Ahmadi, Siddharth Bhandari, Avrim Blum, Chen Dan, Prabhav Jain","journal":"arXiv","year":"2024","doi":"10.48550/arXiv.2406.03458","url":"https://arxiv.org/abs/2406.03458","keyAssumptions":"Adversarial perturbation sets are point sets; distributional robustness through worst-case analysis","keyHypotheses":"Using distribution families as perturbation sets provides better adversarial robustness guarantees","strengths":"Novel theoretical framework; PAC-learning bounds; unifies randomized smoothing and robust learning","weaknesses":"Limited to theoretical analysis; computational complexity may be high; needs practical algorithms","citation":"Ahmadi, S., et al. (2024). Distributional Adversarial Loss. arXiv:2406.03458","notes":"Shows distributional assumptions can be enforced via adversarial training - relevant to enforcement mechanisms","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"hao2025","title":"Towards Better Generalization via Distributional Input Projection Network","authors":"Yifan Hao, Yanxin Lu, Xinwei Shen, Tong Zhang","journal":"arXiv","year":"2025","doi":"10.48550/arXiv.2506.04690","url":"https://arxiv.org/abs/2506.04690","keyAssumptions":"Standard neural networks process deterministic inputs; smoothness improvements require architectural changes","keyHypotheses":"Projecting inputs to learnable distributions at each layer induces smoother loss landscapes and better generalization","strengths":"Practical implementation; works across architectures (ViTs, LLMs, ResNet); consistent improvements; seamless integration","weaknesses":"Computational overhead; hyperparameter sensitivity; limited theoretical analysis of why it works","citation":"Hao, Y., et al. (2025). Towards Better Generalization via Distributional Input Projection Network. arXiv:2506.04690","notes":"Practical implementation of distribution enforcement throughout network layers - directly applicable to DERP","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"lan2019","title":"A Probabilistic Representation of Deep Learning","authors":"Xinjie Lan, Kenneth E. Barner","journal":"arXiv","year":"2019","doi":"10.48550/arXiv.1908.09772","url":"https://arxiv.org/abs/1908.09772","keyAssumptions":"Deep networks are black boxes; probabilistic interpretation is secondary to performance","keyHypotheses":"DNNs can be explicitly interpreted as Bayesian networks with neurons defining Gibbs distributions","strengths":"Clear theoretical framework; explicit probabilistic interpretation; addresses hierarchy and generalization","weaknesses":"Limited to theoretical analysis; validation only on synthetic data; unclear practical implications","citation":"Lan, X., Barner, K.E. (2019). A Probabilistic Representation of Deep Learning. arXiv:1908.09772","notes":"Foundation for understanding distributional assumptions in neural networks - relevant to theoretical grounding","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"paik2023","title":"Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test","authors":"Seunghoon Paik, Michael Celentano, Alden Green, Ryan J. Tibshirani","journal":"arXiv","year":"2023","doi":"10.48550/arXiv.2309.02422","url":"https://arxiv.org/abs/2309.02422","keyAssumptions":"Classical K-S test limited to 1D; multivariate two-sample testing requires complex methods","keyHypotheses":"Neural networks can implement multivariate generalizations of K-S test via ridge splines","strengths":"Strong theoretical foundation; neural network implementation; asymptotically full power; practical optimization via deep learning","weaknesses":"Computational complexity; requires careful hyperparameter tuning; limited empirical evaluation","citation":"Paik, S., et al. (2023). Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test. arXiv:2309.02422","notes":"Direct implementation of statistical testing via neural networks - key to our Random Probe methodology","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"dang2024","title":"Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical VAEs","authors":"Hien Dang, Tho Tran, Tan Nguyen, Nhat Ho","journal":"ICLR","year":"2024","doi":"","url":"https://arxiv.org/abs/2306.05023","keyAssumptions":"Posterior collapse mainly affects standard VAEs; conditional and hierarchical variants less studied","keyHypotheses":"Correlation in conditional VAE and learnable encoder variance in hierarchical VAE cause posterior collapse","strengths":"Rigorous theoretical analysis; extends beyond standard VAE; empirical validation on linear and non-linear cases","weaknesses":"Limited to specific VAE variants; theoretical analysis mostly for linear cases; limited practical solutions","citation":"Dang, H., et al. (2024). Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical VAEs. ICLR","notes":"Theoretical analysis of distributional assumption failures in VAE - critical for understanding when enforcement fails","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"lucas2019","title":"Don't Blame the ELBO! A Linear VAE Perspective on Posterior Collapse","authors":"James Lucas, George Tucker, Roger B. Grosse, Mohammad Norouzi","journal":"NeurIPS","year":"2019","doi":"","url":"https://proceedings.neurips.cc/paper/2019/file/7e3315fe390974fcf25e44a9445bd821-Paper.pdf","keyAssumptions":"ELBO objective causes posterior collapse through KL divergence term; optimization issues secondary","keyHypotheses":"Posterior collapse arises from local maxima in loss surface, not ELBO formulation itself","strengths":"Clear theoretical analysis via linear VAE; connection to pPCA; challenges conventional wisdom; tractable analysis","weaknesses":"Limited to linear case; gap between linear analysis and deep VAE behavior; limited practical solutions","citation":"Lucas, J., et al. (2019). Don't Blame the ELBO! A Linear VAE Perspective on Posterior Collapse. NeurIPS","notes":"Fundamental insight that posterior collapse is optimization problem, not objective design - informs when distribution enforcement can succeed","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"wang2023","title":"Posterior Collapse and Latent Variable Non-identifiability","authors":"Yixin Wang, David M. Blei, John P. Cunningham","journal":"arXiv","year":"2023","doi":"","url":"https://arxiv.org/abs/2301.00537","keyAssumptions":"Posterior collapse is VAE-specific phenomenon; neural networks or variational approximation cause the issue","keyHypotheses":"Posterior collapse occurs if and only if latent variables are non-identifiable in the generative model","strengths":"Fundamental theoretical insight; connects to identifiability theory; proposes practical solution with bijective maps","weaknesses":"Complex mathematical formulation; computational overhead of bijective maps; limited empirical evaluation","citation":"Wang, Y., Blei, D.M., Cunningham, J.P. (2023). Posterior Collapse and Latent Variable Non-identifiability. arXiv:2301.00537","notes":"Critical theoretical foundation - shows distributional assumptions must be identifiable for enforcement to work","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"takida2022","title":"Preventing Posterior Collapse Induced by Oversmoothing in Gaussian VAE","authors":"Yuhta Takida, Wei-Hsiang Liao, Toshimitsu Uesaka, Shusuke Takahashi, Yuki Mitsufuji","journal":"arXiv","year":"2022","doi":"","url":"https://arxiv.org/abs/2102.08663","keyAssumptions":"Fixed variance parameters in Gaussian VAE; oversmoothing is unavoidable side effect","keyHypotheses":"Adaptive variance parameter control can prevent oversmoothing-induced posterior collapse","strengths":"Clear connection between variance and posterior collapse; practical AR-ELBO algorithm; improved FID scores","weaknesses":"Limited to Gaussian VAE; hyperparameter sensitivity; computational overhead of adaptive methods","citation":"Takida, Y., et al. (2022). Preventing Posterior Collapse Induced by Oversmoothing in Gaussian VAE. arXiv:2102.08663","notes":"Shows importance of proper variance parameter tuning - relevant to parameter selection in distribution enforcement","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"lin2019","title":"Balancing Reconstruction Quality and Regularisation in Evidence Lower Bound for Variational Autoencoders","authors":"Shuyu Lin, Stephen Roberts, Niki Trigoni, Ronald Clark","journal":"arXiv","year":"2019","doi":"","url":"https://arxiv.org/abs/1909.03765","keyAssumptions":"Fixed noise variance in Gaussian likelihood; manual tuning of reconstruction-regularization trade-off","keyHypotheses":"Learning noise variance in p(x|z) automatically provides optimal reconstruction-regularization balance","strengths":"Simple and intuitive solution; automatic trade-off optimization; uncertainty estimation capability; improved generation quality","weaknesses":"Limited to Gaussian likelihoods; may not generalize to other distributions; uncertainty estimation not thoroughly evaluated","citation":"Lin, S., et al. (2019). Balancing Reconstruction Quality and Regularisation in Evidence Lower Bound for Variational Autoencoders. arXiv:1909.03765","notes":"Shows how distributional parameters can be learned for better enforcement - relevant to automatic parameter selection","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"seo2024","title":"Rate-Adaptive Quantization: A Multi-Rate Codebook Adaptation for Vector Quantization-based Generative Models","authors":"Jiwan Seo, Joonhyuk Kang","journal":"arXiv","year":"2024","doi":"","url":"https://arxiv.org/abs/2405.14222","keyAssumptions":"Single fixed-rate codebooks in VQ models; extensive retraining needed for different rates","keyHypotheses":"Multi-rate codebook adaptation from single baseline can provide flexible rate-distortion trade-offs","strengths":"Single system handles diverse requirements; data-driven approach; practical clustering procedure; outperforms fixed-rate baselines","weaknesses":"Complexity in codebook management; potential overfitting to training distribution; computational overhead","citation":"Seo, J., Kang, J. (2024). Rate-Adaptive Quantization: A Multi-Rate Codebook Adaptation for Vector Quantization-based Generative Models. arXiv:2405.14222","notes":"Shows adaptive codebook learning - relevant to making distribution enforcement adaptive to data requirements","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"huijben2024","title":"Residual Quantization with Implicit Neural Codebooks","authors":"Iris A. M. Huijben, Matthijs Douze, Matthew Muckley, Ruud J. G. van Sloun, Jakob Verbeek","journal":"ICML","year":"2024","doi":"","url":"https://arxiv.org/abs/2401.14732","keyAssumptions":"Fixed codebooks per quantization step; error distribution independence across steps","keyHypotheses":"Specialized codebooks dependent on previous quantization steps can account for error distribution dependencies","strengths":"Strong theoretical motivation; superior performance (12 vs 16 bytes); accounts for distribution dependencies; practical implementation","weaknesses":"Increased model complexity; computational overhead; limited to residual quantization; needs careful initialization","citation":"Huijben, I.A.M., et al. (2024). Residual Quantization with Implicit Neural Codebooks. ICML","notes":"Shows how accounting for distributional dependencies improves quantization - relevant to multi-step distribution enforcement","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"zheng2023","title":"Online Clustered Codebook","authors":"Chuanxia Zheng, Andrea Vedaldi","journal":"arXiv","year":"2023","doi":"10.48550/arXiv.2307.15139","url":"https://arxiv.org/abs/2307.15139","keyAssumptions":"Equal update probability for all codevectors; gradient-based updates sufficient for all codevectors","keyHypotheses":"Clustered updates using encoded features as anchors can revive dead codevectors and improve coverage","strengths":"Addresses fundamental codebook collapse problem; simple integration; improved codebook utilization; general applicability","weaknesses":"Heuristic approach; limited theoretical analysis; computational overhead; may introduce bias toward certain features","citation":"Zheng, C., Vedaldi, A. (2023). Online Clustered Codebook. arXiv:2307.15139","notes":"Addresses distributional coverage in codebook learning - relevant to ensuring comprehensive distribution enforcement","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"tamkin2023","title":"Codebook Features: Sparse and Discrete Interpretability for Neural Networks","authors":"Alex Tamkin, Mohammad Taufeeque","journal":"Stanford AI Lab Blog","year":"2023","doi":"","url":"https://ai.stanford.edu/blog/codebook-features/","keyAssumptions":"Dense continuous representations necessary for neural network expressivity; interpretability requires sacrificing performance","keyHypotheses":"Sparse discrete representations via VQ can maintain performance while improving interpretability","strengths":"Practical implementation; minimal accuracy drop; interpretable representations; works with transformers","weaknesses":"Limited theoretical analysis; interpretability gains not quantified; computational overhead not analyzed","citation":"Tamkin, A., Taufeeque, M. (2023). Codebook Features: Sparse and Discrete Interpretability for Neural Networks. Stanford AI Lab Blog","notes":"Shows VQ can maintain distributional properties while improving interpretability - relevant to verifiable distribution enforcement","addedDate":"2025-08-26T19:46:00.000Z"}
{"id":"bosman2023","title":"Robustness Distributions in Neural Network Verification","authors":"Annelot W. Bosman, Aaron Berger, Holger H. Hoos, Jan N. van Rijn","journal":"JAIR","year":"2023","doi":"","url":"https://www.jair.org/index.php/jair/article/view/18403","keyAssumptions":"Binary robust/non-robust classification sufficient; individual input analysis adequate","keyHypotheses":"Critical epsilon distributions follow log-normal distribution; K-S tests can verify distributional properties of robustness","strengths":"Rigorous statistical analysis; K-S test validation; extensive empirical evaluation; novel robustness distribution perspective","weaknesses":"Limited to MNIST; computational cost of complete verification; theoretical analysis incomplete","citation":"Bosman, A.W., et al. (2023). Robustness Distributions in Neural Network Verification. JAIR","notes":"Direct application of K-S testing to neural network analysis - validates our Random Probe approach for verification","addedDate":"2025-08-26T19:46:00.000Z"}